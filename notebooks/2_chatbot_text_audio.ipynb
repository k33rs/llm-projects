{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "d006b2ea-9dfe-49c7-88a9-a5a0775185fd",
   "metadata": {},
   "source": [
    "# Multimodal chatbot with streaming\n",
    "\n",
    "Features a Gradio UI, text and audio streaming, use of the system prompt to add expertise, and the ability to switch between models. TODO: add tools!\n",
    "\n",
    "Example commercial applications: a language tutor, a company onboarding solution, a companion AI to a course, etc."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a07e7793-b8f5-44f4-aded-5562f633271a",
   "metadata": {},
   "outputs": [],
   "source": [
    "from dotenv import load_dotenv\n",
    "import litellm\n",
    "import gradio as gr\n",
    "import base64, io, os, struct\n",
    "import json"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d62f7ca0",
   "metadata": {},
   "outputs": [],
   "source": [
    "load_dotenv(override=True)\n",
    "openai_api_key = os.getenv('OPENAI_API_KEY')\n",
    "groq_api_key = os.getenv('GROQ_API_KEY')\n",
    "\n",
    "def validate_api_keys(api_keys, prefixes):\n",
    "    for api_key, prefix in zip(api_keys, prefixes):\n",
    "        if not api_key or not api_key.startswith(prefix) or len(api_key) <= 10:\n",
    "            raise ValueError(f\"Invalid API key: {api_key}\")\n",
    "\n",
    "validate_api_keys(\n",
    "    api_keys=[openai_api_key, groq_api_key],\n",
    "    prefixes=['sk-proj-', 'gsk_']\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2bc5d417",
   "metadata": {},
   "outputs": [],
   "source": [
    "MODEL_CHOICES_AUDIO = [\n",
    "    'gpt-4o-mini-audio-preview',\n",
    "    'gpt-4o-audio-preview',\n",
    "]\n",
    "\n",
    "MODEL_CHOICES_TEXT = [\n",
    "    'groq/openai/gpt-oss-120b',\n",
    "    'gpt-5-nano-2025-08-07',\n",
    "    'gpt-4.1-nano-2025-04-14',\n",
    "]\n",
    "\n",
    "MODEL_CHOICES_STT = [\n",
    "    \"gpt-4o-mini-transcribe\",\n",
    "    \"gpt-4o-transcribe\",\n",
    "    \"whisper-1\",\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "05dfb0a3",
   "metadata": {},
   "outputs": [],
   "source": [
    "sys_prompt_default = \"\"\"You are a helpful programming assistant.\n",
    "You provide exhaustive and detailed answers to programming questions,\n",
    "with relevant code examples.\"\"\"\n",
    "\n",
    "sys_prompt = input(\"Enter system prompt: \") or sys_prompt_default"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d0b1d93f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def make_wav_header(data_size, sample_rate=24000, num_channels=1, bits_per_sample=16):\n",
    "    \"\"\"Return a 44-byte WAV header for a PCM16 chunk.\"\"\"\n",
    "    byte_rate = sample_rate * num_channels * bits_per_sample // 8\n",
    "    block_align = num_channels * bits_per_sample // 8\n",
    "    riff_chunk_size = 36 + data_size\n",
    "\n",
    "    return struct.pack(\n",
    "        '<4sI4s4sIHHIIHH4sI',\n",
    "        b'RIFF',\n",
    "        riff_chunk_size,\n",
    "        b'WAVE',\n",
    "        b'fmt ',\n",
    "        16,\n",
    "        1,                   # PCM\n",
    "        num_channels,\n",
    "        sample_rate,\n",
    "        byte_rate,\n",
    "        block_align,\n",
    "        bits_per_sample,\n",
    "        b'data',\n",
    "        data_size\n",
    "    )\n",
    "\n",
    "def pcm16_to_wav(pcm_bytes, sample_rate=24000):\n",
    "    header = make_wav_header(len(pcm_bytes), sample_rate)\n",
    "    return header + pcm_bytes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2de03897",
   "metadata": {},
   "outputs": [],
   "source": [
    "def messages_from(history):\n",
    "    return [{\"role\": \"system\", \"content\": sys_prompt}] + \\\n",
    "        [{\"role\": h[\"role\"], \"content\": h[\"content\"]} for h in history]\n",
    "\n",
    "def add_to_history(history, prompt, role):\n",
    "    return history + [{\"role\": role, \"content\": prompt}]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d9f17793",
   "metadata": {},
   "outputs": [],
   "source": [
    "def chat(model, history):\n",
    "    messages = messages_from(history)\n",
    "    response = litellm.completion(\n",
    "        model=model,\n",
    "        messages=messages,\n",
    "        stream=True,\n",
    "    )\n",
    "\n",
    "    text_stream = \"\"\n",
    "    for chunk in response:\n",
    "        delta = chunk.choices[0].delta.content or \"\"\n",
    "        text_stream += delta\n",
    "        yield add_to_history(messages, text_stream, \"assistant\")\n",
    "\n",
    "def chat_with_audio(model, history):\n",
    "    messages = messages_from(history)\n",
    "    response = litellm.completion(\n",
    "        model=model,\n",
    "        messages=messages,\n",
    "        stream=True,\n",
    "        modalities=[\"text\", \"audio\"],\n",
    "        audio={\"voice\": \"alloy\", \"format\": \"pcm16\"},\n",
    "    )\n",
    "\n",
    "    text_stream = []\n",
    "    audio_buffer = io.BytesIO()\n",
    "    chunk_count = 0\n",
    "\n",
    "    for chunk in response:\n",
    "        if not (audio := getattr(chunk.choices[0].delta, \"audio\", None)):\n",
    "            continue\n",
    "        \n",
    "        # stream text\n",
    "        if text_chunk := audio.get(\"transcript\"):\n",
    "            text_stream.append(text_chunk)\n",
    "            yield add_to_history(messages, \"\".join(text_stream), \"assistant\"), gr.update()\n",
    "            chunk_count += 1\n",
    "\n",
    "        # stream audio\n",
    "        if audio_data := audio.get(\"data\"):\n",
    "            audio_pcm = base64.b64decode(audio_data)\n",
    "            audio_buffer.write(audio_pcm)\n",
    "            # periodically yield audio chunks\n",
    "            if chunk_count >= 20:\n",
    "                audio_wav = pcm16_to_wav(audio_buffer.getvalue())\n",
    "                yield gr.update(), audio_wav\n",
    "                # reset buffer\n",
    "                audio_buffer.seek(0)\n",
    "                audio_buffer.truncate(0)\n",
    "                chunk_count = 0\n",
    "\n",
    "    if audio_buffer.getbuffer().nbytes > 0:\n",
    "        yield gr.update(), pcm16_to_wav(audio_buffer.getvalue())\n",
    "\n",
    "def speech_to_text(audio, model):\n",
    "    res = litellm.transcription(\n",
    "        file=open(audio, \"rb\"),\n",
    "        model=model,\n",
    "        response_format=\"text\",\n",
    "        stream=False,\n",
    "    )\n",
    "    return res.text.strip()\n",
    "\n",
    "def speech_to_text_stream(audio, model):\n",
    "    response = litellm.transcription(\n",
    "        file=open(audio, \"rb\"),\n",
    "        model=model,\n",
    "        response_format=\"json\",\n",
    "        stream=True,\n",
    "    )\n",
    "    for _, chunk_data in response:\n",
    "        if not chunk_data:\n",
    "            continue\n",
    "        chunk_lines = chunk_data.replace('data: ', '').strip().split('\\r\\n\\r\\n')\n",
    "        for line in chunk_lines:\n",
    "            try:\n",
    "                chunk_json = json.loads(line)\n",
    "            except json.JSONDecodeError:\n",
    "                continue\n",
    "            if chunk_json[\"type\"] == \"transcript.text.delta\":\n",
    "                yield chunk_json[\"delta\"]\n",
    "            elif chunk_json[\"type\"] == \"transcript.text.done\":\n",
    "                yield chunk_json[\"text\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "491d76b1",
   "metadata": {},
   "outputs": [],
   "source": [
    "def update_chatbot_msg(hist, msg):\n",
    "    return add_to_history(hist, msg, \"user\"), ''\n",
    "\n",
    "def update_chatbot_audio(hist, audio, transcr_model):\n",
    "    transcript = speech_to_text(audio, transcr_model)\n",
    "    return add_to_history(hist, transcript, \"user\"), None\n",
    "\n",
    "def update_chatbot_audio_stream(hist, audio, transcr_model):\n",
    "    for chunk in speech_to_text_stream(audio, transcr_model):\n",
    "        yield add_to_history(hist, chunk, \"user\"), None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "506916e4",
   "metadata": {},
   "outputs": [],
   "source": [
    "with gr.Blocks() as demo:\n",
    "    with gr.Row():\n",
    "        text_model = gr.Dropdown(choices=MODEL_CHOICES_TEXT, value=MODEL_CHOICES_TEXT[0], label=\"Text Model\")\n",
    "        audio_model = gr.Dropdown(choices=MODEL_CHOICES_AUDIO, value=MODEL_CHOICES_AUDIO[0], label=\"Audio Model\")\n",
    "        stt_model = gr.Dropdown(choices=MODEL_CHOICES_STT, value=MODEL_CHOICES_STT[0], label=\"Transcription Model\")\n",
    "    with gr.Row():\n",
    "        chatbot = gr.Chatbot()\n",
    "    with gr.Row():\n",
    "        msg = gr.Textbox(label=\"Ask me a technical question\")\n",
    "    with gr.Row():\n",
    "        audio_in = gr.Audio(sources=[\"microphone\"], type=\"filepath\", label=\"\")\n",
    "        audio_out = gr.Audio(autoplay=True, streaming=True)\n",
    "\n",
    "    msg.submit(update_chatbot_msg, inputs=[chatbot, msg], outputs=[chatbot, msg]) \\\n",
    "        .then(lambda: (None, None), outputs=[audio_in, audio_out]) \\\n",
    "        .then(chat, inputs=[text_model, chatbot], outputs=[chatbot])\n",
    "\n",
    "    audio_in.stop_recording(update_chatbot_audio, inputs=[chatbot, audio_in, stt_model], outputs=[chatbot, audio_in]) \\\n",
    "        .then(lambda: \"\", outputs=[msg]) \\\n",
    "        .then(chat_with_audio, inputs=[audio_model, chatbot], outputs=[chatbot, audio_out])\n",
    "\n",
    "demo.launch(inbrowser=True, share=False, debug=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "portfolio",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
